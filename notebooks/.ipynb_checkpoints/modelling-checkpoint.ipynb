{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/preprocessed_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraudulent</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marketing intern u ny new york we re food we v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>customer service cloud video production nz auc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commissioning machinery assistant cma u ia wev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text\n",
       "fraudulent                                                   \n",
       "0           marketing intern u ny new york we re food we v...\n",
       "0           customer service cloud video production nz auc...\n",
       "0           commissioning machinery assistant cma u ia wev..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../data/X_train.csv', index_col=0)\n",
    "y_train = pd.read_csv('../data/y_train.csv')['fraudulent']\n",
    "X_test = pd.read_csv('../data/X_test.csv', index_col=0)\n",
    "y_test = pd.read_csv('../data/y_test.csv')['fraudulent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [i/10 for i in range(0, 11)]\n",
    "fit_prior = [True, False]\n",
    "param_dist = {\"alpha\": alpha, \"fit_prior\": fit_prior}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MultinomialNB(),\n",
       "             param_grid={'alpha': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
       "                                   0.9, 1.0],\n",
       "                         'fit_prior': [True, False]})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search = GridSearchCV(estimator=nb, param_grid=param_dist, cv=5)\n",
    "rand_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=0.1)\n"
     ]
    }
   ],
   "source": [
    "best_nb = rand_search.best_estimator_\n",
    "print(best_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = best_nb\n",
    "nb.fit(X_train, y_train)\n",
    "y_predict_nb = nb.predict(X_test)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5985\n",
      "           1       0.92      0.59      0.72       273\n",
      "\n",
      "    accuracy                           0.98      6258\n",
      "   macro avg       0.95      0.79      0.85      6258\n",
      "weighted avg       0.98      0.98      0.98      6258\n",
      "\n",
      "Execution time: 1.619954800605774 min\n"
     ]
    }
   ],
   "source": [
    "nb_report = classification_report(y_test, y_predict_nb)\n",
    "print(nb_report)\n",
    "print(\"Execution time: %s min\" % ((end_time - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a terrible start, but not quite where I want the scores to be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "lr = LogisticRegression()\n",
    "dual = [True, False]\n",
    "l1_ratio = [i/10 for i in range(1, 10)]\n",
    "param_dist = {\"dual\": dual, \"l1_ratio\": l1_ratio, \"n_jobs\": [-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'dual': [True, False],\n",
       "                         'l1_ratio': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
       "                                      0.9],\n",
       "                         'n_jobs': [-1]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(lr, param_grid=param_dist, scoring='f1', cv=5)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(l1_ratio=0.1, n_jobs=-1)\n"
     ]
    }
   ],
   "source": [
    "print(best_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_lr = best_lr.predict(X_test)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      5985\n",
      "           1       0.96      0.38      0.54       273\n",
      "\n",
      "    accuracy                           0.97      6258\n",
      "   macro avg       0.97      0.69      0.76      6258\n",
      "weighted avg       0.97      0.97      0.97      6258\n",
      "\n",
      "Execution time: 8.905601799488068 min\n"
     ]
    }
   ],
   "source": [
    "lr_report = classification_report(y_test, y_predict_lr)\n",
    "print(lr_report)\n",
    "print(\"Execution time: %s min\" % ((end_time - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I guess its safe to say that logistic regression is not the best model. The F1 score for the fraudulent jobs is way too low. The execution time is also longer than I would like (feeling a bit impatient today). On to the next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passive Aggresive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "pac = PassiveAggressiveClassifier()\n",
    "loss = ['hinge', 'squared_hinge']\n",
    "shuffle = [True, False]\n",
    "param_dist = {\"shuffle\": shuffle, \"loss\": loss, \"n_jobs\": [-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=PassiveAggressiveClassifier(),\n",
       "             param_grid={'loss': ['hinge', 'squared_hinge'], 'n_jobs': [-1],\n",
       "                         'shuffle': [True, False]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pac, param_grid=param_dist, scoring='f1', cv=5)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pac = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveClassifier(n_jobs=-1, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "print(best_pac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_pac = best_pac.predict(X_test)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      5985\n",
      "           1       0.97      0.65      0.78       273\n",
      "\n",
      "    accuracy                           0.98      6258\n",
      "   macro avg       0.98      0.83      0.89      6258\n",
      "weighted avg       0.98      0.98      0.98      6258\n",
      "\n",
      "Execution time: 1.8393629988034566 min\n"
     ]
    }
   ],
   "source": [
    "pac_report = classification_report(y_test, y_predict_pac)\n",
    "print(sgd_report)\n",
    "print(\"Execution time: %s min\" % ((end_time - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best classifier so far. An above 0.80 F1 score for the fraudelent class is pretty decent for the amount of time it took to execute. I am pretty happy with this and can conclude this is the best model for the job from the models I've tested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
