{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final notebook, I will begin to modelling and decide which model is best for classifying job postings as real or fake. For each model I will tune hyperparameters with cross validation and calculate the total execution time. \n",
    "\n",
    "*Note:* For  reference regarding the execution time, I am running a Mac with Dual-Core Intel i5 3.1 GHz with 8 GB of RAM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll start by loading some of the tools I'll need for the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll load in the preprocessed data just so I have it for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/preprocessed_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fraudulent</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marketing intern we re food we ve created grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>customer service cloud video production second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>commissioning machinery assistant cma valor se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text\n",
       "fraudulent                                                   \n",
       "0           marketing intern we re food we ve created grou...\n",
       "0           customer service cloud video production second...\n",
       "0           commissioning machinery assistant cma valor se..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And most importantly I'll load in the testing and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../data/X_train.csv', index_col=0)\n",
    "y_train = pd.read_csv('../data/y_train.csv')['fraudulent']\n",
    "X_test = pd.read_csv('../data/X_test.csv', index_col=0)\n",
    "y_test = pd.read_csv('../data/y_test.csv')['fraudulent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the fun part! I am going to choose 3 different model and each will be tuned using `GridSearchCV` with a CV of 5. The models that I have chosen are:\n",
    "- Naive Bayes\n",
    "- K-Nearest Neighbor\n",
    "- Passive Aggressive Classifier\n",
    "\n",
    "The reason I chose these models is because of their speed. In my experience, I know Naive Bayes and KNN to be pretty efficient in terms of speed and memory. This will be my first time modelling with a Passive Aggressive Classifier, but from what I've read, it seems pretty efficient too.\n",
    "\n",
    "However, before I even begin thinking of getting my hands dirty with modelling, I'll first run a dummy model as a basline. This will help me determine how good or bad my actual models are by comparision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(strategy='most_frequent')\n",
    "dummy.fit(X_train, y_train)\n",
    "y_predict_dummy = dummy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      5143\n",
      "           1       0.00      0.00      0.00       221\n",
      "\n",
      "    accuracy                           0.96      5364\n",
      "   macro avg       0.48      0.50      0.49      5364\n",
      "weighted avg       0.92      0.96      0.94      5364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_report = classification_report(y_test, y_predict_dummy)\n",
    "print(dummy_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, one could say the dummy model performed really well if you just look at the weighted F1 and overall accuracy. The truth is, that it isn't that great (after all it is a dummy model). Since the data is imbalanced, favoring the real jobs, the predicted label for each record is going to be real. The overall accuracy might be high, but the F1 for the fake jobs is what really matters here. This is the reality of dealing with imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first real model is good ole' Naive Bayes. Naive Bayes can work quite well for NLP tasks and I know it to be very effcient in terms of memory and speed. I won't go to crazy with the hyperparameters and I'll only tune a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [i/10 for i in range(0, 5)]\n",
    "fit_prior = [True, False]\n",
    "param_dist = {\"alpha\": alpha, \"fit_prior\": fit_prior}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MultinomialNB(),\n",
       "             param_grid={'alpha': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                         'fit_prior': [True, False]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_search = GridSearchCV(estimator=nb, param_grid=param_dist, cv=5)\n",
    "rand_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=0.0, fit_prior=False)\n"
     ]
    }
   ],
   "source": [
    "best_nb = rand_search.best_estimator_\n",
    "print(best_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = best_nb\n",
    "nb.fit(X_train, y_train)\n",
    "y_predict_nb = nb.predict(X_test)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5143\n",
      "           1       0.80      0.71      0.75       221\n",
      "\n",
      "    accuracy                           0.98      5364\n",
      "   macro avg       0.89      0.85      0.87      5364\n",
      "weighted avg       0.98      0.98      0.98      5364\n",
      "\n",
      "Execution time: 0.6473629991213481 min\n"
     ]
    }
   ],
   "source": [
    "nb_report = classification_report(y_test, y_predict_nb)\n",
    "print(nb_report)\n",
    "print(\"Execution time: %s min\" % ((end_time - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good start and kind of how I expected. Naive Bayes can be pretty useful for NLP tasks and run fairly quick. A 0.75 F1 score for the fraudulent jobs is nothing to be ashamed about, but I know I can do better. On to the next model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passive Aggresive Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next model I've chosen to test is a Passive Aggresive Classifier. To be quite honest, I don't know much on how this model actually works. All I've heard about it is that it performs well for NLP tasks. I figured I would give it a shot here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "pac = PassiveAggressiveClassifier()\n",
    "loss = ['hinge', 'squared_hinge']\n",
    "shuffle = [True, False]\n",
    "param_dist = {\"shuffle\": shuffle, \"loss\": loss, \"n_jobs\": [-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=PassiveAggressiveClassifier(),\n",
       "             param_grid={'loss': ['hinge', 'squared_hinge'], 'n_jobs': [-1],\n",
       "                         'shuffle': [True, False]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pac, param_grid=param_dist, scoring='f1', cv=5)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pac = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveClassifier(n_jobs=-1)\n"
     ]
    }
   ],
   "source": [
    "print(best_pac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_pac = best_pac.predict(X_test)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5143\n",
      "           1       0.82      0.78      0.80       221\n",
      "\n",
      "    accuracy                           0.98      5364\n",
      "   macro avg       0.90      0.89      0.89      5364\n",
      "weighted avg       0.98      0.98      0.98      5364\n",
      "\n",
      "Execution time: 1.6690042932828268 min\n"
     ]
    }
   ],
   "source": [
    "pac_report = classification_report(y_test, y_predict_pac)\n",
    "print(pac_report)\n",
    "print(\"Execution time: %s min\" % ((end_time - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty solid. Overall, the accuracy is pretty high and the F1 scores for the fraudlent postings are no less than 0.80. Also, the execution time is pretty short, so thats a plus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last up is KNN. KNN I'll tune the number of neighbors for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "knn = KNeighborsClassifier()\n",
    "n_neighbors = [i for i in range(2, 6)]\n",
    "param_dist = {\"n_neighbors\": n_neighbors, \"weights\": ['distance'], \"n_jobs\": [-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_jobs': [-1], 'n_neighbors': [2, 3, 4, 5],\n",
       "                         'weights': ['distance']},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(knn, param_grid=param_dist, scoring='f1', cv=5)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights='distance')\n"
     ]
    }
   ],
   "source": [
    "print(best_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_knn = best_knn.predict(X_test)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      5143\n",
      "           1       0.83      0.79      0.81       221\n",
      "\n",
      "    accuracy                           0.98      5364\n",
      "   macro avg       0.91      0.89      0.90      5364\n",
      "weighted avg       0.98      0.98      0.98      5364\n",
      "\n",
      "Execution time: 2.2565786997477213 min\n"
     ]
    }
   ],
   "source": [
    "knn_report = classification_report(y_test, y_predict_knn)\n",
    "print(knn_report)\n",
    "print(\"Execution time: %s min\" % ((end_time - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a pretty similar score to the PAC. The KNN is slightly more accurate, but not by much. The run time is also slightly longer than the previous model as well. I am sure this could be improved slightly if I chose more parameters to tune, but I think this is the model I will stick with for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all the models tested, I have settled on using KNN. Right now, all I have to show for its performance are the F1 scores, but one of the best ways to understand the performance is to plot the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fpr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cd/30fw6byx50j2fw87436pvvyc0000gn/T/ipykernel_39060/859483892.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_knn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fpr' is not defined"
     ]
    }
   ],
   "source": [
    "y_scores = best_knn.predict_proba(X_test)\n",
    "pr, tpr, threshold = roc_curve(y_test, y_scores[:, 1])\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve of kNN')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
